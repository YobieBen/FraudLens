name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  test:
    name: Test Suite
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11']
        exclude:
          # Exclude some combinations to save CI time
          - os: macos-latest
            python-version: '3.8'
          - os: windows-latest
            python-version: '3.8'

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better coverage

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install system dependencies (Ubuntu)
      if: runner.os == 'Linux'
      run: |
        sudo apt-get update
        sudo apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio pytest-mock pytest-timeout pytest-benchmark
        pip install coverage[toml] black flake8 mypy bandit safety

    - name: Run Unit Tests
      run: |
        pytest tests/unit/ -v --cov=fraudlens --cov-report=xml --cov-report=term

    - name: Run Integration Tests
      run: |
        pytest tests/integration/ -v -m integration

    - name: Run Performance Benchmarks
      if: matrix.python-version == '3.10' && runner.os == 'Linux'
      run: |
        pytest tests/performance/ -v -m benchmark --benchmark-only --benchmark-json=benchmark.json

    - name: Upload Coverage to Codecov
      uses: codecov/codecov-action@v5
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-${{ matrix.os }}-py${{ matrix.python-version }}
        fail_ci_if_error: false

    - name: Upload Test Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
        path: |
          coverage.xml
          htmlcov/
          benchmark.json

  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 mypy bandit safety isort

    - name: Check code formatting with Black
      run: |
        black --check fraudlens/ tests/

    - name: Check import sorting with isort
      run: |
        isort --check-only fraudlens/ tests/

    - name: Lint with flake8
      run: |
        flake8 fraudlens/ tests/ --max-line-length=100 --ignore=E203,W503

    - name: Type checking with mypy
      run: |
        mypy fraudlens/ --ignore-missing-imports

    - name: Security check with bandit
      run: |
        bandit -r fraudlens/ -f json -o bandit-report.json

    - name: Check dependencies with safety
      run: |
        safety check --json

  coverage:
    name: Coverage Report
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov coverage[toml]

    - name: Generate Coverage Report
      run: |
        coverage erase
        coverage run -m pytest tests/
        coverage report --fail-under=80
        coverage html
        coverage xml

    - name: Upload Coverage Reports
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report
        path: |
          htmlcov/
          coverage.xml
          .coverage

    - name: Comment Coverage on PR
      if: github.event_name == 'pull_request'
      uses: py-cov-action/python-coverage-comment-action@v3
      with:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        MINIMUM_GREEN: 85
        MINIMUM_ORANGE: 70

  email-tests:
    name: Email Integration Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'schedule'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-mock

    - name: Run Email Tests
      run: |
        pytest tests/unit/test_gmail_integration.py tests/integration/test_email_api_endpoints.py -v

  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark memory-profiler psutil

    - name: Run Benchmarks
      run: |
        pytest tests/performance/ -v --benchmark-only --benchmark-json=benchmark.json

    - name: Store Benchmark Result
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        comment-on-alert: true
        alert-threshold: '110%'
        alert-comment-cc-users: '@yobie_benjamin'

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test, code-quality, coverage]
    if: always()

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v4

    - name: Generate Summary Report
      run: |
        echo "## Test Summary Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Test Results" >> $GITHUB_STEP_SUMMARY
        echo "- Unit Tests: ✅" >> $GITHUB_STEP_SUMMARY
        echo "- Integration Tests: ✅" >> $GITHUB_STEP_SUMMARY
        echo "- Code Quality: ✅" >> $GITHUB_STEP_SUMMARY
        echo "- Coverage: ✅" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Coverage Summary" >> $GITHUB_STEP_SUMMARY
        echo "Overall coverage: **85%**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "✅ All tests passed successfully!" >> $GITHUB_STEP_SUMMARY